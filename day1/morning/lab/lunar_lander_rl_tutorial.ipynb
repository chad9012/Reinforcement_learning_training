{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Interactive Reinforcement Learning Tutorial\n",
        "## Understanding the Basics with Gymnasium\n",
        "\n",
        "Welcome to this interactive tutorial on Reinforcement Learning! We'll explore the fundamental concepts using practical examples with OpenAI's Gymnasium library.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 1. What is Reinforcement Learning?\n",
        "\n",
        "**Reinforcement Learning (RL)** is a learning paradigm where an **agent** learns from interaction with an **environment** to maximize cumulative reward over time.\n",
        "\n",
        "### Key Characteristics:\n",
        "- ğŸ¯ **Goal-oriented**: Agent learns to achieve objectives\n",
        "- ğŸ”„ **Trial and error**: Learning through experience\n",
        "- â° **Sequential decision making**: Actions affect future states\n",
        "- ğŸ† **Reward-driven**: Behavior shaped by feedback\n",
        "\n",
        "### RL vs Other Learning Paradigms:\n",
        "- **Supervised Learning**: Learn from labeled examples\n",
        "- **Unsupervised Learning**: Find patterns in data\n",
        "- **Reinforcement Learning**: Learn from interaction and feedback\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 2. The Markov Decision Process (MDP) Framework\n",
        "\n",
        "RL problems are modeled as **Markov Decision Processes (MDPs)** with five key components:\n",
        "\n",
        "### ğŸ—ï¸ MDP Components:\n",
        "1. **S**: Set of **States** - All possible environment configurations\n",
        "2. **A**: Set of **Actions** - All possible agent actions  \n",
        "3. **P(s'|s,a)**: **Transition Probability** - Probability of reaching state s' from state s after action a\n",
        "4. **R(s,a)**: **Reward Function** - Immediate reward for taking action a in state s\n",
        "5. **Î³ (gamma)**: **Discount Factor** - Importance of future rewards (0 â‰¤ Î³ â‰¤ 1)\n",
        "\n",
        "### ğŸ¯ Objective:\n",
        "Learn a **policy Ï€(a|s)** that maximizes expected cumulative reward (return).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ Reinforcement Learning with LunarLander\n",
        "\n",
        "## ğŸ“š Table of Contents\n",
        "\n",
        "Welcome to hands-on reinforcement learning! In this tutorial, we'll:\n",
        "\n",
        "1. ğŸ“¦ Set up the required packages\n",
        "2. ğŸŒ™ Explore the LunarLander environment\n",
        "3. ğŸ² Test a random agent baseline\n",
        "4. ğŸ® Take manual control of the lander\n",
        "\n",
        "### ğŸ¯ Learning Objectives:\n",
        "- Understand MDP components in practice\n",
        "- Analyze state and action spaces\n",
        "- Experience the challenge of RL environments\n",
        "- Compare random vs intelligent control\n",
        "\n",
        "Let's begin our lunar landing mission! ğŸŒ™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… gymnasium already installed\n",
            "ğŸ“¦ Installing gymnasium[box2d]...\n",
            "Requirement already satisfied: gymnasium[box2d] in /home/pc6/anaconda3/envs/rl_env/lib/python3.10/site-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /home/pc6/anaconda3/envs/rl_env/lib/python3.10/site-packages (from gymnasium[box2d]) (2.2.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /home/pc6/.local/lib/python3.10/site-packages (from gymnasium[box2d]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /home/pc6/.local/lib/python3.10/site-packages (from gymnasium[box2d]) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /home/pc6/.local/lib/python3.10/site-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /home/pc6/.local/lib/python3.10/site-packages (from gymnasium[box2d]) (2.3.5)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /home/pc6/anaconda3/envs/rl_env/lib/python3.10/site-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /home/pc6/.local/lib/python3.10/site-packages (from gymnasium[box2d]) (4.3.1)\n",
            "âœ… gymnasium[box2d] installed successfully\n",
            "âœ… numpy already installed\n",
            "âœ… matplotlib already installed\n",
            "âœ… pygame already installed\n",
            "\n",
            "ğŸš€ All packages ready for lunar landing!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (run this first!)\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install_package(package):\n",
        "    try:\n",
        "        __import__(package)\n",
        "        print(f\"âœ… {package} already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"ğŸ“¦ Installing {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "        print(f\"âœ… {package} installed successfully\")\n",
        "\n",
        "# Install required packages\n",
        "install_package(\"gymnasium\")\n",
        "install_package(\"gymnasium[box2d]\")  # For LunarLander\n",
        "install_package(\"numpy\")\n",
        "install_package(\"matplotlib\")\n",
        "install_package(\"pygame\")\n",
        "\n",
        "print(\"\\nğŸš€ All packages ready for lunar landing!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“š Libraries imported successfully!\n",
            "ğŸ‹ï¸ Gymnasium version: 1.1.1\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pygame\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(\"ğŸ“š Libraries imported successfully!\")\n",
        "print(f\"ğŸ‹ï¸ Gymnasium version: {gym.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ LunarLander-v2 Environment Analysis\n",
            "==================================================\n",
            "ğŸ—ï¸  State Space: Box([ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
            "  -0.         -0.       ], [ 2.5        2.5       10.        10.         6.2831855 10.\n",
            "  1.         1.       ], (8,), float32)\n",
            "    - Type: <class 'gymnasium.spaces.box.Box'>\n",
            "    - Shape: (8,)\n",
            "    - Low bounds: [ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
            "  -0.         -0.       ]\n",
            "    - High bounds: [ 2.5        2.5       10.        10.         6.2831855 10.\n",
            "  1.         1.       ]\n",
            "\n",
            "ğŸ¯ Action Space: Discrete(4)\n",
            "    - Type: <class 'gymnasium.spaces.discrete.Discrete'>\n",
            "    - Number of actions: 4\n",
            "    - Actions:\n",
            "      â€¢ 0: Do nothing\n",
            "      â€¢ 1: Fire left orientation engine\n",
            "      â€¢ 2: Fire main engine\n",
            "      â€¢ 3: Fire right orientation engine\n",
            "\n",
            "ğŸ† Reward Range: (-âˆ, +âˆ) - Continuous reward system\n",
            "ğŸ“Š Max Episode Steps: 1000\n",
            "\n",
            "ğŸ” State Vector Details (8 dimensions):\n",
            "    0: Horizontal position (x)\n",
            "    1: Vertical position (y)\n",
            "    2: Horizontal velocity (vx)\n",
            "    3: Vertical velocity (vy)\n",
            "    4: Angle (Î¸)\n",
            "    5: Angular velocity (Ï‰)\n",
            "    6: Left leg contact (boolean)\n",
            "    7: Right leg contact (boolean)\n",
            "\n",
            "ğŸ¯ Mission Objective:\n",
            "    â€¢ Land the lunar module safely between the flags\n",
            "    â€¢ Reward â‰¥ 200 points = Successful landing\n",
            "    â€¢ Reward â‰¥ 100 points = Decent attempt\n",
            "    â€¢ Negative rewards = Crashed or poor landing\n"
          ]
        }
      ],
      "source": [
        "## ğŸŒ™ Exploring the LunarLander Environment\n",
        "\n",
        "# Create and explore the LunarLander environment\n",
        "env = gym.make('LunarLander-v3')\n",
        "\n",
        "print(\"ğŸš€ LunarLander-v2 Environment Analysis\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Environment spaces\n",
        "print(f\"ğŸ—ï¸  State Space: {env.observation_space}\")\n",
        "print(f\"    - Type: {type(env.observation_space)}\")\n",
        "print(f\"    - Shape: {env.observation_space.shape}\")\n",
        "print(f\"    - Low bounds: {env.observation_space.low}\")\n",
        "print(f\"    - High bounds: {env.observation_space.high}\")\n",
        "\n",
        "print(f\"\\nğŸ¯ Action Space: {env.action_space}\")\n",
        "print(f\"    - Type: {type(env.action_space)}\")\n",
        "print(f\"    - Number of actions: {env.action_space.n}\")\n",
        "print(f\"    - Actions:\")\n",
        "print(f\"      â€¢ 0: Do nothing\")\n",
        "print(f\"      â€¢ 1: Fire left orientation engine\")\n",
        "print(f\"      â€¢ 2: Fire main engine\")\n",
        "print(f\"      â€¢ 3: Fire right orientation engine\")\n",
        "\n",
        "# Handle reward range safely\n",
        "try:\n",
        "    print(f\"\\nğŸ† Reward Range: {env.reward_range}\")\n",
        "except AttributeError:\n",
        "    print(f\"\\nğŸ† Reward Range: (-âˆ, +âˆ) - Continuous reward system\")\n",
        "\n",
        "print(f\"ğŸ“Š Max Episode Steps: {env.spec.max_episode_steps}\")\n",
        "\n",
        "# Show state space details\n",
        "print(f\"\\nğŸ” State Vector Details (8 dimensions):\")\n",
        "state_descriptions = [\n",
        "    \"0: Horizontal position (x)\",\n",
        "    \"1: Vertical position (y)\", \n",
        "    \"2: Horizontal velocity (vx)\",\n",
        "    \"3: Vertical velocity (vy)\",\n",
        "    \"4: Angle (Î¸)\",\n",
        "    \"5: Angular velocity (Ï‰)\",\n",
        "    \"6: Left leg contact (boolean)\",\n",
        "    \"7: Right leg contact (boolean)\"\n",
        "]\n",
        "\n",
        "for desc in state_descriptions:\n",
        "    print(f\"    {desc}\")\n",
        "\n",
        "print(f\"\\nğŸ¯ Mission Objective:\")\n",
        "print(f\"    â€¢ Land the lunar module safely between the flags\")\n",
        "print(f\"    â€¢ Reward â‰¥ 200 points = Successful landing\")\n",
        "print(f\"    â€¢ Reward â‰¥ 100 points = Decent attempt\")\n",
        "print(f\"    â€¢ Negative rewards = Crashed or poor landing\")\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” Sample Initial State:\n",
            "==============================\n",
            "State[0]:   0.0023 - Horizontal position (x)\n",
            "State[1]:   1.4181 - Vertical position (y)\n",
            "State[2]:   0.2326 - Horizontal velocity (vx)\n",
            "State[3]:   0.3205 - Vertical velocity (vy)\n",
            "State[4]:  -0.0027 - Angle (Î¸)\n",
            "State[5]:  -0.0527 - Angular velocity (Ï‰)\n",
            "State[6]:   0.0000 - Left leg contact\n",
            "State[7]:   0.0000 - Right leg contact\n",
            "\n",
            "ğŸ’¡ Interpretation:\n",
            "   â€¢ Lander starts at position (0.002, 1.418)\n",
            "   â€¢ Initial velocity: (0.233, 0.320)\n",
            "   â€¢ Angle: -0.003 radians (-0.2Â°)\n",
            "   â€¢ Legs touching ground: False (left), False (right)\n"
          ]
        }
      ],
      "source": [
        "## ğŸ“Š Sample State Observation\n",
        "\n",
        "# Let's see what a typical state looks like\n",
        "env = gym.make('LunarLander-v3')\n",
        "state, info = env.reset(seed=42)  # Set seed for reproducibility\n",
        "\n",
        "print(\"ğŸ” Sample Initial State:\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "state_labels = [\n",
        "    \"Horizontal position (x)\",\n",
        "    \"Vertical position (y)\", \n",
        "    \"Horizontal velocity (vx)\",\n",
        "    \"Vertical velocity (vy)\",\n",
        "    \"Angle (Î¸)\",\n",
        "    \"Angular velocity (Ï‰)\",\n",
        "    \"Left leg contact\",\n",
        "    \"Right leg contact\"\n",
        "]\n",
        "\n",
        "for i, (value, label) in enumerate(zip(state, state_labels)):\n",
        "    print(f\"State[{i}]: {value:8.4f} - {label}\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ Interpretation:\")\n",
        "print(f\"   â€¢ Lander starts at position ({state[0]:.3f}, {state[1]:.3f})\")\n",
        "print(f\"   â€¢ Initial velocity: ({state[2]:.3f}, {state[3]:.3f})\")\n",
        "print(f\"   â€¢ Angle: {state[4]:.3f} radians ({np.degrees(state[4]):.1f}Â°)\")\n",
        "print(f\"   â€¢ Legs touching ground: {bool(state[6])} (left), {bool(state[7])} (right)\")\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¤– Random Agent class created successfully!\n",
            "ğŸ“Š Episode runner function ready with human-readable output!\n",
            "ğŸ¯ Demo function ready - use run_random_agent_demo(env) to see it in action!\n"
          ]
        }
      ],
      "source": [
        "## ğŸ² Random Agent Implementation\n",
        "\n",
        "class RandomAgent:\n",
        "    \"\"\"Random agent that selects actions randomly\"\"\"\n",
        "    \n",
        "    def __init__(self, action_space):\n",
        "        self.action_space = action_space\n",
        "        \n",
        "    def select_action(self, state):\n",
        "        \"\"\"Select a random action\"\"\"\n",
        "        return self.action_space.sample()\n",
        "    \n",
        "    def learn(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Random agents don't learn\"\"\"\n",
        "        pass\n",
        "\n",
        "def run_episode(env, agent, max_steps=1000, render=False, verbose=False):\n",
        "    \"\"\"Run a single episode and return episode data\"\"\"\n",
        "    state, info = env.reset()\n",
        "    total_reward = 0\n",
        "    steps = 0\n",
        "    action_counts = {0: 0, 1: 0, 2: 0, 3: 0}  # Track action usage\n",
        "    \n",
        "    for step in range(max_steps):\n",
        "        if render:\n",
        "            env.render()\n",
        "            time.sleep(0.02)\n",
        "            \n",
        "        action = agent.select_action(state)\n",
        "        action_counts[action] += 1\n",
        "        \n",
        "        next_state, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        \n",
        "        if verbose and step % 100 == 0:\n",
        "            action_name = {0: \"DO NOTHING\", 1: \"FIRE LEFT\", 2: \"FIRE MAIN\", 3: \"FIRE RIGHT\"}[action]\n",
        "            print(f\"  Step {step}: Action={action_name}, Reward={reward:.2f}, Total={total_reward:.1f}\")\n",
        "        \n",
        "        agent.learn(state, action, reward, next_state, done)\n",
        "        \n",
        "        total_reward += reward\n",
        "        steps += 1\n",
        "        state = next_state\n",
        "        \n",
        "        if done:\n",
        "            break\n",
        "    \n",
        "    # Enhanced return with human-readable action summary\n",
        "    action_names = {0: \"DO NOTHING\", 1: \"FIRE LEFT\", 2: \"FIRE MAIN\", 3: \"FIRE RIGHT\"}\n",
        "    action_summary = {action_names[k]: v for k, v in action_counts.items()}\n",
        "    \n",
        "    return {\n",
        "        'total_reward': total_reward,\n",
        "        'steps': steps,\n",
        "        'success': total_reward >= 200,\n",
        "        'decent': total_reward >= 100,\n",
        "        'action_counts': action_counts,\n",
        "        'action_summary': action_summary,\n",
        "        'terminated': terminated if 'terminated' in locals() else False\n",
        "    }\n",
        "\n",
        "def print_episode_summary(episode_data):\n",
        "    \"\"\"Print a human-readable summary of the episode\"\"\"\n",
        "    print(f\"\\nğŸš€ Episode Summary:\")\n",
        "    print(f\"   Total Reward: {episode_data['total_reward']:.1f}\")\n",
        "    print(f\"   Steps Taken: {episode_data['steps']}\")\n",
        "    print(f\"   Success: {'âœ… YES' if episode_data['success'] else 'âŒ NO'}\")\n",
        "    print(f\"   Decent Landing: {'âœ… YES' if episode_data['decent'] else 'âŒ NO'}\")\n",
        "    \n",
        "    print(f\"\\nğŸ® Action Usage:\")\n",
        "    for action_name, count in episode_data['action_summary'].items():\n",
        "        percentage = (count / episode_data['steps']) * 100\n",
        "        print(f\"   {action_name}: {count} times ({percentage:.1f}%)\")\n",
        "    \n",
        "    print(f\"\\nğŸ¯ Performance: {'ğŸ† EXCELLENT' if episode_data['success'] else 'ğŸ‘ GOOD' if episode_data['decent'] else 'ğŸ’¥ CRASHED'}\")\n",
        "\n",
        "def run_random_agent_demo(env, num_episodes=5, render=True, verbose=True):\n",
        "    \"\"\"Run a demonstration of the random agent with human-readable output\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"ğŸ² RANDOM AGENT DEMONSTRATION\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(\"Watch the random agent attempt to land the lunar lander!\")\n",
        "    print(f\"Running {num_episodes} episodes...\")\n",
        "    \n",
        "    agent = RandomAgent(env.action_space)\n",
        "    all_results = []\n",
        "    \n",
        "    for episode in range(num_episodes):\n",
        "        print(f\"\\nğŸŒ™ Episode {episode + 1}/{num_episodes}\")\n",
        "        print(\"-\" * 40)\n",
        "        \n",
        "        episode_data = run_episode(env, agent, render=render, verbose=verbose)\n",
        "        all_results.append(episode_data)\n",
        "        \n",
        "        # Print summary for each episode\n",
        "        print_episode_summary(episode_data)\n",
        "        \n",
        "        if render and episode < num_episodes - 1:\n",
        "            input(\"\\nPress Enter to continue to next episode...\")\n",
        "    \n",
        "    # Overall statistics\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"ğŸ“Š OVERALL RANDOM AGENT STATISTICS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    total_episodes = len(all_results)\n",
        "    successful_episodes = sum(1 for r in all_results if r['success'])\n",
        "    decent_episodes = sum(1 for r in all_results if r['decent'])\n",
        "    avg_reward = sum(r['total_reward'] for r in all_results) / total_episodes\n",
        "    avg_steps = sum(r['steps'] for r in all_results) / total_episodes\n",
        "    \n",
        "    print(f\"Total Episodes: {total_episodes}\")\n",
        "    print(f\"Successful Landings (â‰¥200 reward): {successful_episodes} ({successful_episodes/total_episodes*100:.1f}%)\")\n",
        "    print(f\"Decent Landings (â‰¥100 reward): {decent_episodes} ({decent_episodes/total_episodes*100:.1f}%)\")\n",
        "    print(f\"Average Reward: {avg_reward:.1f}\")\n",
        "    print(f\"Average Steps: {avg_steps:.1f}\")\n",
        "    \n",
        "    # Action distribution across all episodes\n",
        "    total_actions = {0: 0, 1: 0, 2: 0, 3: 0}\n",
        "    for result in all_results:\n",
        "        for action, count in result['action_counts'].items():\n",
        "            total_actions[action] += count\n",
        "    \n",
        "    total_action_count = sum(total_actions.values())\n",
        "    action_names = {0: \"DO NOTHING\", 1: \"FIRE LEFT\", 2: \"FIRE MAIN\", 3: \"FIRE RIGHT\"}\n",
        "    \n",
        "    print(f\"\\nğŸ® Overall Action Distribution:\")\n",
        "    for action_id, count in total_actions.items():\n",
        "        percentage = (count / total_action_count) * 100\n",
        "        print(f\"   {action_names[action_id]}: {count} times ({percentage:.1f}%)\")\n",
        "    \n",
        "    return all_results\n",
        "\n",
        "print(\"ğŸ¤– Random Agent class created successfully!\")\n",
        "print(\"ğŸ“Š Episode runner function ready with human-readable output!\")\n",
        "print(\"ğŸ¯ Demo function ready - use run_random_agent_demo(env) to see it in action!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Testing Random Agent on LunarLander\n",
            "==================================================\n",
            "ğŸ® Running 5 episodes with random actions...\n",
            "\n",
            "ğŸš€ Episode 1:\n",
            "   Steps: 71, Reward: -91.8 - âŒ Crashed/Failed\n",
            "   Actions used: Do nothing=21, Left=19, Main=16, Right=15\n",
            "\n",
            "ğŸš€ Episode 2:\n",
            "   Steps: 64, Reward: -115.2 - âŒ Crashed/Failed\n",
            "   Actions used: Do nothing=17, Left=15, Main=17, Right=15\n",
            "\n",
            "ğŸš€ Episode 3:\n",
            "   Steps: 71, Reward: -104.4 - âŒ Crashed/Failed\n",
            "   Actions used: Do nothing=12, Left=18, Main=17, Right=24\n",
            "\n",
            "ğŸš€ Episode 4:\n",
            "   Steps: 120, Reward: -350.1 - âŒ Crashed/Failed\n",
            "   Actions used: Do nothing=31, Left=25, Main=39, Right=25\n",
            "\n",
            "ğŸš€ Episode 5:\n",
            "   Steps: 62, Reward: -146.2 - âŒ Crashed/Failed\n",
            "   Actions used: Do nothing=13, Left=17, Main=15, Right=17\n",
            "\n",
            "ğŸ“Š Random Agent Results Summary:\n",
            "===================================\n",
            "ğŸ¯ Success Rate: 0/5 (0%)\n",
            "ğŸŸ¡ Decent Attempts: 0/5 (0%)\n",
            "ğŸ“ˆ Average Reward: -161.5 Â± 96.0\n",
            "ğŸ† Best Episode: -91.8\n",
            "ğŸ’¥ Worst Episode: -350.1\n",
            "\n",
            "ğŸ® Action Distribution Across All Episodes:\n",
            "   Do nothing: 94 (24.2%)\n",
            "   Fire left: 94 (24.2%)\n",
            "   Fire main: 104 (26.8%)\n",
            "   Fire right: 96 (24.7%)\n",
            "\n",
            "ğŸ’¡ Observations:\n",
            "   â€¢ Random actions rarely lead to successful landings\n",
            "   â€¢ Most episodes end in crashes or poor performance\n",
            "   â€¢ This shows the need for intelligent control strategies\n",
            "   â€¢ Success rate: 0% (vs ~90%+ for trained agents)\n"
          ]
        }
      ],
      "source": [
        "## ğŸ² Testing Random Agent - 5 Episodes\n",
        "\n",
        "print(\"ğŸš€ Testing Random Agent on LunarLander\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create environment and random agent\n",
        "env = gym.make('LunarLander-v3',render_mode='human')\n",
        "random_agent = RandomAgent(env.action_space)\n",
        "\n",
        "# Test random agent for 5 episodes\n",
        "random_rewards = []\n",
        "successes = 0\n",
        "decent_attempts = 0\n",
        "all_action_counts = {0: 0, 1: 0, 2: 0, 3: 0}\n",
        "\n",
        "print(\"ğŸ® Running 5 episodes with random actions...\\n\")\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"ğŸš€ Episode {i+1}:\")\n",
        "    episode_data = run_episode(env, random_agent, max_steps=1000, verbose=False)\n",
        "    \n",
        "    random_rewards.append(episode_data['total_reward'])\n",
        "    \n",
        "    # Update counters\n",
        "    if episode_data['success']:\n",
        "        successes += 1\n",
        "        status = \"âœ… SUCCESS!\"\n",
        "    elif episode_data['decent']:\n",
        "        decent_attempts += 1\n",
        "        status = \"ğŸŸ¡ Decent attempt\"\n",
        "    else:\n",
        "        status = \"âŒ Crashed/Failed\"\n",
        "    \n",
        "    # Aggregate action counts\n",
        "    for action, count in episode_data['action_counts'].items():\n",
        "        all_action_counts[action] += count\n",
        "    \n",
        "    print(f\"   Steps: {episode_data['steps']}, Reward: {episode_data['total_reward']:.1f} - {status}\")\n",
        "    print(f\"   Actions used: Do nothing={episode_data['action_counts'][0]}, Left={episode_data['action_counts'][1]}, Main={episode_data['action_counts'][2]}, Right={episode_data['action_counts'][3]}\")\n",
        "    print()\n",
        "\n",
        "# Calculate statistics\n",
        "avg_reward = np.mean(random_rewards)\n",
        "std_reward = np.std(random_rewards)\n",
        "best_reward = max(random_rewards)\n",
        "worst_reward = min(random_rewards)\n",
        "\n",
        "print(\"ğŸ“Š Random Agent Results Summary:\")\n",
        "print(\"=\" * 35)\n",
        "print(f\"ğŸ¯ Success Rate: {successes}/5 ({successes*20}%)\")\n",
        "print(f\"ğŸŸ¡ Decent Attempts: {decent_attempts}/5 ({decent_attempts*20}%)\")\n",
        "print(f\"ğŸ“ˆ Average Reward: {avg_reward:.1f} Â± {std_reward:.1f}\")\n",
        "print(f\"ğŸ† Best Episode: {best_reward:.1f}\")\n",
        "print(f\"ğŸ’¥ Worst Episode: {worst_reward:.1f}\")\n",
        "\n",
        "print(f\"\\nğŸ® Action Distribution Across All Episodes:\")\n",
        "total_actions = sum(all_action_counts.values())\n",
        "for action, count in all_action_counts.items():\n",
        "    action_names = ['Do nothing', 'Fire left', 'Fire main', 'Fire right']\n",
        "    percentage = (count / total_actions) * 100\n",
        "    print(f\"   {action_names[action]}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ Observations:\")\n",
        "print(f\"   â€¢ Random actions rarely lead to successful landings\")\n",
        "print(f\"   â€¢ Most episodes end in crashes or poor performance\")\n",
        "print(f\"   â€¢ This shows the need for intelligent control strategies\")\n",
        "print(f\"   â€¢ Success rate: {successes*20}% (vs ~90%+ for trained agents)\")\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ LunarLander Manual Control Started!\n",
            "Goal: Land the spacecraft safely between the flags!\n",
            "Controls:\n",
            "  â† Left Arrow  = Fire left engine (rotate right)\n",
            "  â†’ Right Arrow = Fire right engine (rotate left)\n",
            "  â†‘ Up Arrow    = Fire main engine (thrust up)\n",
            "  â†“ Down Arrow  = Do nothing\n",
            "  ESC or Close Window = Quit\n",
            "  R = Reset episode\n",
            "==================================================\n",
            "ğŸ’¡ Tips:\n",
            "  - Use main engine to slow descent\n",
            "  - Use side engines to control rotation and horizontal movement\n",
            "  - Land gently between the yellow flags!\n",
            "  - Legs must touch ground first for safe landing\n",
            "==================================================\n",
            "Step  20 | X:  -0.04 | Y:   1.46 | Vel: (-0.20,-0.16) | Angle:  0.05 | Reward:   -1.4 | Total:    8.6\n",
            "Step  40 | X:  -0.08 | Y:   1.27 | Vel: (-0.20,-0.69) | Angle:  0.09 | Reward:   -1.2 | Total:  -23.1\n",
            "ğŸš€ MAIN ENGINE FIRING!\n",
            "Step  60 | X:  -0.12 | Y:   0.83 | Vel: (-0.21,-1.13) | Angle:  0.13 | Reward:    4.4 | Total:  -28.3\n",
            "Step  80 | X:  -0.18 | Y:   0.41 | Vel: (-0.44,-0.79) | Angle:  0.16 | Reward:    2.3 | Total:   27.9\n",
            "Step 100 | X:  -0.29 | Y:   0.13 | Vel: (-0.65,-0.45) | Angle:  0.19 | Reward:   -0.1 | Total:   41.0\n",
            "Step 107 | X:  -0.34 | Y:   0.08 | Vel: (-0.56,-0.13) | Angle:  0.04 | Reward:   10.4 | Total:   74.0\n",
            "â­• Engines off\n",
            "Step 117 | X:  -0.39 | Y:   0.06 | Vel: (-0.44,-0.07) | Angle: -0.44 | Reward: -100.0 | Total:  -58.1\n",
            "\n",
            "==================================================\n",
            "ğŸ’¥ ROUGH LANDING! You survived but damaged the lander.\n",
            "ğŸ“Š Episode 1 Results:\n",
            "   Final Score: -58.1\n",
            "   Steps taken: 117\n",
            "   Final position: (-0.39, 0.06)\n",
            "   Final velocity: (-0.44, -0.07)\n",
            "ğŸ¥‰ RATING: NOVICE PILOT\n",
            "==================================================\n",
            "ğŸ”„ Resetting in 3 seconds... (Press R to reset immediately)\n",
            "ğŸ†• Episode 2 started\n",
            "Step  20 | X:   0.07 | Y:   1.13 | Vel: ( 0.32,-0.86) | Angle: -0.08 | Reward:   -0.9 | Total:  -26.0\n",
            "ğŸš€ MAIN ENGINE FIRING!\n",
            "Step  40 | X:   0.14 | Y:   0.80 | Vel: ( 0.45,-0.48) | Angle: -0.15 | Reward:    1.3 | Total:   19.6\n",
            "ğŸ”¥ LEFT ENGINE FIRING!\n",
            "Step  60 | X:   0.26 | Y:   0.68 | Vel: ( 0.65,-0.17) | Angle: -0.24 | Reward:    0.4 | Total:   12.1\n",
            "ğŸš€ MAIN ENGINE FIRING!\n",
            "Step  80 | X:   0.37 | Y:   0.49 | Vel: ( 0.47,-0.53) | Angle:  0.14 | Reward:   -2.4 | Total:   27.9\n",
            "Step 100 | X:   0.42 | Y:   0.35 | Vel: (-0.08,-0.19) | Angle:  0.76 | Reward:   -5.0 | Total:   16.9\n",
            "Step 108 | X:   0.39 | Y:   0.32 | Vel: (-0.56,-0.15) | Angle:  1.01 | Reward:  -11.5 | Total:  -44.3\n",
            "ğŸ”¥ RIGHT ENGINE FIRING!\n",
            "Step 120 | X:   0.32 | Y:   0.25 | Vel: (-0.59,-0.38) | Angle:  1.25 | Reward:   -0.7 | Total:  -70.9\n",
            "ğŸš€ MAIN ENGINE FIRING!\n",
            "ğŸ”¥ RIGHT ENGINE FIRING!\n",
            "â­• Engines off\n",
            "Step 136 | X:   0.22 | Y:   0.06 | Vel: (-0.77,-0.65) | Angle:  1.06 | Reward:   11.7 | Total:  -55.6\n",
            "ğŸš€ MAIN ENGINE FIRING!\n",
            "Step 140 | X:   0.18 | Y:   0.02 | Vel: (-1.00,-0.44) | Angle:  1.28 | Reward:  -18.9 | Total:  -82.4\n",
            "ğŸ¦µ Landing legs touching: RIGHT\n",
            "Step 141 | X:   0.17 | Y:   0.02 | Vel: (-1.05,-0.45) | Angle:  1.40 | Reward:  -16.7 | Total:  -99.1\n",
            "â­• Engines off\n",
            "ğŸ”¥ RIGHT ENGINE FIRING!\n",
            "Step 143 | X:   0.15 | Y:   0.00 | Vel: (-1.03,-0.43) | Angle:  1.67 | Reward:  -23.0 | Total: -131.5\n",
            "Step 144 | X:   0.14 | Y:  -0.00 | Vel: (-1.03,-0.45) | Angle:  1.81 | Reward:  -13.4 | Total: -144.9\n",
            "â­• Engines off\n",
            "Step 145 | X:   0.13 | Y:  -0.00 | Vel: (-0.95, 0.00) | Angle:  1.83 | Reward: -100.0 | Total: -244.9\n",
            "\n",
            "==================================================\n",
            "ğŸ’¥ CRASH! The lander was destroyed.\n",
            "ğŸ“Š Episode 2 Results:\n",
            "   Final Score: -244.9\n",
            "   Steps taken: 145\n",
            "   Final position: (0.13, -0.00)\n",
            "   Final velocity: (-0.95, 0.00)\n",
            "ğŸ’€ RATING: NEEDS MORE PRACTICE\n",
            "==================================================\n",
            "ğŸ”„ Resetting in 3 seconds... (Press R to reset immediately)\n",
            "ğŸ†• Episode 3 started\n",
            "Step  20 | X:   0.12 | Y:   1.50 | Vel: ( 0.55,-0.07) | Angle: -0.13 | Reward:   -0.8 | Total:   -4.9\n",
            "Step  40 | X:   0.22 | Y:   1.34 | Vel: ( 0.55,-0.61) | Angle: -0.25 | Reward:   -1.3 | Total:  -29.1\n",
            "ğŸ”¥ LEFT ENGINE FIRING!\n",
            "â­• Engines off\n",
            "Step  60 | X:   0.32 | Y:   0.95 | Vel: ( 0.40,-1.12) | Angle: -0.08 | Reward:    2.3 | Total:  -12.6\n",
            "ğŸš€ MAIN ENGINE FIRING!\n",
            "Step  80 | X:   0.39 | Y:   0.51 | Vel: ( 0.11,-0.78) | Angle:  0.40 | Reward:   -1.4 | Total:   26.0\n",
            "Step 100 | X:   0.34 | Y:   0.24 | Vel: (-0.69,-0.56) | Angle:  0.85 | Reward:   -5.9 | Total:  -11.7\n",
            "ğŸ”¥ RIGHT ENGINE FIRING!\n",
            "Step 112 | X:   0.24 | Y:   0.07 | Vel: (-0.79,-0.73) | Angle:  1.01 | Reward:   10.1 | Total:  -22.6\n",
            "Step 113 | X:   0.23 | Y:   0.07 | Vel: (-0.75,-0.20) | Angle:  1.09 | Reward:   24.0 | Total:    1.5\n",
            "Step 117 | X:   0.20 | Y:   0.07 | Vel: (-0.74,-0.11) | Angle:  1.43 | Reward:  -17.6 | Total:  -38.6\n",
            "Step 120 | X:   0.18 | Y:   0.06 | Vel: (-0.74,-0.17) | Angle:  1.67 | Reward:   -7.2 | Total:  -60.6\n",
            "â­• Engines off\n",
            "Step 129 | X:   0.11 | Y:   0.02 | Vel: (-0.69, 0.03) | Angle:  2.25 | Reward: -100.0 | Total: -213.4\n",
            "\n",
            "==================================================\n",
            "ğŸ’¥ CRASH! The lander was destroyed.\n",
            "ğŸ“Š Episode 3 Results:\n",
            "   Final Score: -213.4\n",
            "   Steps taken: 129\n",
            "   Final position: (0.11, 0.02)\n",
            "   Final velocity: (-0.69, 0.03)\n",
            "ğŸ’€ RATING: NEEDS MORE PRACTICE\n",
            "==================================================\n",
            "ğŸ”„ Resetting in 3 seconds... (Press R to reset immediately)\n",
            "ğŸ†• Episode 4 started\n",
            "Step  20 | X:   0.10 | Y:   1.08 | Vel: ( 0.47,-0.96) | Angle: -0.11 | Reward:   -0.8 | Total:  -22.5\n",
            "ğŸ”¥ LEFT ENGINE FIRING!\n",
            "â­• Engines off\n",
            "ğŸš€ MAIN ENGINE FIRING!\n",
            "Step  40 | X:   0.19 | Y:   0.56 | Vel: ( 0.49,-1.17) | Angle: -0.15 | Reward:    4.0 | Total:    2.1\n",
            "Step  59 | X:   0.30 | Y:   0.14 | Vel: ( 0.66,-0.84) | Angle: -0.18 | Reward:   10.6 | Total:   48.8\n",
            "Step  60 | X:   0.30 | Y:   0.12 | Vel: ( 0.51,-0.70) | Angle: -0.17 | Reward:   21.4 | Total:   70.2\n",
            "ğŸ¦µ Landing legs touching: LEFT\n",
            "Step  63 | X:   0.32 | Y:   0.09 | Vel: ( 0.13,-0.16) | Angle:  0.01 | Reward: -100.0 | Total:  -19.5\n",
            "\n",
            "==================================================\n",
            "ğŸ’¥ ROUGH LANDING! You survived but damaged the lander.\n",
            "ğŸ“Š Episode 4 Results:\n",
            "   Final Score: -19.5\n",
            "   Steps taken: 63\n",
            "   Final position: (0.32, 0.09)\n",
            "   Final velocity: (0.13, -0.16)\n",
            "ğŸ¥‰ RATING: NOVICE PILOT\n",
            "==================================================\n",
            "ğŸ”„ Resetting in 3 seconds... (Press R to reset immediately)\n",
            "ğŸ†• Episode 5 started\n",
            "â­• Engines off\n",
            "Step  20 | X:  -0.10 | Y:   1.52 | Vel: (-0.49,-0.03) | Angle:  0.12 | Reward:   -0.6 | Total:   -0.5\n",
            "Step  40 | X:  -0.20 | Y:   1.38 | Vel: (-0.49,-0.57) | Angle:  0.23 | Reward:   -1.3 | Total:  -24.2\n",
            "ğŸ”¥ RIGHT ENGINE FIRING!\n",
            "â­• Engines off\n",
            "ğŸš€ MAIN ENGINE FIRING!\n",
            "Step  60 | X:  -0.29 | Y:   1.01 | Vel: (-0.44,-0.93) | Angle:  0.13 | Reward:    3.3 | Total:  -10.7\n",
            "Step  80 | X:  -0.39 | Y:   0.68 | Vel: (-0.45,-0.55) | Angle: -0.13 | Reward:   -0.2 | Total:   42.3\n",
            "Step 100 | X:  -0.45 | Y:   0.49 | Vel: (-0.09,-0.27) | Angle: -0.36 | Reward:   -0.2 | Total:   68.0\n",
            "Step 120 | X:  -0.40 | Y:   0.47 | Vel: ( 0.57, 0.11) | Angle: -0.56 | Reward:   -4.2 | Total:   17.0\n",
            "â­• Engines off\n",
            "ğŸ”¥ LEFT ENGINE FIRING!\n",
            "Step 140 | X:  -0.25 | Y:   0.47 | Vel: ( 0.75,-0.21) | Angle: -0.73 | Reward:    1.0 | Total:  -12.9\n",
            "â­• Engines off\n",
            "ğŸš€ MAIN ENGINE FIRING!\n",
            "Step 160 | X:  -0.11 | Y:   0.30 | Vel: ( 0.86,-0.32) | Angle: -0.32 | Reward:    0.3 | Total:   33.2\n",
            "Step 180 | X:   0.09 | Y:   0.24 | Vel: ( 0.93, 0.08) | Angle:  0.20 | Reward:   -0.2 | Total:   43.8\n",
            "â­• Engines off\n",
            "ğŸ”¥ RIGHT ENGINE FIRING!\n",
            "Step 200 | X:   0.26 | Y:   0.28 | Vel: ( 0.81,-0.10) | Angle:  0.72 | Reward:   -3.4 | Total:  -11.7\n",
            "â­• Engines off\n",
            "ğŸš€ MAIN ENGINE FIRING!\n",
            "Step 218 | X:   0.38 | Y:   0.19 | Vel: ( 0.35,-0.19) | Angle:  0.84 | Reward:   18.1 | Total:   21.1\n",
            "Step 219 | X:   0.39 | Y:   0.18 | Vel: ( 0.26,-0.12) | Angle:  0.81 | Reward:   13.4 | Total:   34.5\n",
            "Step 220 | X:   0.39 | Y:   0.18 | Vel: ( 0.23,-0.12) | Angle:  0.78 | Reward:   -4.6 | Total:   29.9\n",
            "Step 221 | X:   0.39 | Y:   0.18 | Vel: ( 0.17,-0.10) | Angle:  0.74 | Reward:   19.1 | Total:   49.1\n",
            "â­• Engines off\n",
            "Step 232 | X:   0.39 | Y:   0.14 | Vel: (-0.02,-0.27) | Angle:  0.34 | Reward:   11.3 | Total:   82.8\n",
            "Step 235 | X:   0.39 | Y:   0.12 | Vel: (-0.08,-0.25) | Angle:  0.32 | Reward:   11.7 | Total:   95.7\n",
            "Step 240 | X:   0.38 | Y:   0.10 | Vel: (-0.17,-0.17) | Angle:  0.33 | Reward:    0.1 | Total:   99.2\n",
            "ğŸ¦µ Landing legs touching: LEFT, RIGHT\n",
            "Step 242 | X:   0.38 | Y:   0.09 | Vel: (-0.22,-0.06) | Angle:  0.35 | Reward: -100.0 | Total:   -0.9\n",
            "\n",
            "==================================================\n",
            "ğŸ’¥ ROUGH LANDING! You survived but damaged the lander.\n",
            "ğŸ“Š Episode 5 Results:\n",
            "   Final Score: -0.9\n",
            "   Steps taken: 242\n",
            "   Final position: (0.38, 0.09)\n",
            "   Final velocity: (-0.22, -0.06)\n",
            "ğŸ¥‰ RATING: NOVICE PILOT\n",
            "==================================================\n",
            "ğŸ”„ Resetting in 3 seconds... (Press R to reset immediately)\n",
            "ğŸ†• Episode 6 started\n",
            "Step  20 | X:   0.08 | Y:   1.38 | Vel: ( 0.39,-0.33) | Angle: -0.09 | Reward:   -1.4 | Total:  -12.5\n",
            "ğŸ”¥ LEFT ENGINE FIRING!\n",
            "Step  40 | X:   0.16 | Y:   1.11 | Vel: ( 0.31,-0.85) | Angle: -0.10 | Reward:    1.2 | Total:  -26.2\n",
            "â­• Engines off\n",
            "ğŸš€ MAIN ENGINE FIRING!\n",
            "Step  60 | X:   0.20 | Y:   0.68 | Vel: ( 0.01,-0.84) | Angle:  0.40 | Reward:    0.7 | Total:  -11.9\n",
            "ğŸ”¥ RIGHT ENGINE FIRING!\n",
            "Step  80 | X:   0.16 | Y:   0.33 | Vel: (-0.21,-0.93) | Angle:  0.78 | Reward:   -0.4 | Total:  -30.6\n",
            "ğŸš€ MAIN ENGINE FIRING!\n",
            "ğŸ”¥ RIGHT ENGINE FIRING!\n",
            "Step  96 | X:   0.08 | Y:   0.00 | Vel: (-0.69,-0.03) | Angle:  0.74 | Reward: -100.0 | Total: -117.7\n",
            "\n",
            "==================================================\n",
            "ğŸ’¥ CRASH! The lander was destroyed.\n",
            "ğŸ“Š Episode 6 Results:\n",
            "   Final Score: -117.7\n",
            "   Steps taken: 96\n",
            "   Final position: (0.08, 0.00)\n",
            "   Final velocity: (-0.69, -0.03)\n",
            "ğŸ’€ RATING: NEEDS MORE PRACTICE\n",
            "==================================================\n",
            "ğŸ”„ Resetting in 3 seconds... (Press R to reset immediately)\n",
            "ğŸ†• Episode 7 started\n",
            "â­• Engines off\n",
            "Step  20 | X:  -0.16 | Y:   1.15 | Vel: (-0.76,-0.83) | Angle:  0.18 | Reward:   -1.1 | Total:  -23.0\n",
            "ğŸ”š Closing environment...\n",
            "âœ… Cleanup complete!\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "import pygame\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Initialize pygame properly\n",
        "pygame.init()\n",
        "\n",
        "# Initialize environment with human rendering\n",
        "env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
        "obs, _ = env.reset()\n",
        "\n",
        "print(\"ğŸš€ LunarLander Manual Control Started!\")\n",
        "print(\"Goal: Land the spacecraft safely between the flags!\")\n",
        "print(\"Controls:\")\n",
        "print(\"  â† Left Arrow  = Fire left engine (rotate right)\")\n",
        "print(\"  â†’ Right Arrow = Fire right engine (rotate left)\")\n",
        "print(\"  â†‘ Up Arrow    = Fire main engine (thrust up)\")\n",
        "print(\"  â†“ Down Arrow  = Do nothing\")\n",
        "print(\"  ESC or Close Window = Quit\")\n",
        "print(\"  R = Reset episode\")\n",
        "print(\"=\" * 50)\n",
        "print(\"ğŸ’¡ Tips:\")\n",
        "print(\"  - Use main engine to slow descent\")\n",
        "print(\"  - Use side engines to control rotation and horizontal movement\")\n",
        "print(\"  - Land gently between the yellow flags!\")\n",
        "print(\"  - Legs must touch ground first for safe landing\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Map keys to actions for LunarLander\n",
        "# LunarLander actions: 0=nothing, 1=fire left, 2=fire main, 3=fire right\n",
        "KEY_TO_ACTION = {\n",
        "    pygame.K_DOWN: 0,   # Do nothing\n",
        "    pygame.K_LEFT: 1,   # Fire left engine\n",
        "    pygame.K_UP: 2,     # Fire main engine\n",
        "    pygame.K_RIGHT: 3,  # Fire right engine\n",
        "}\n",
        "\n",
        "clock = pygame.time.Clock()\n",
        "running = True\n",
        "action = 0  # Start with 'do nothing'\n",
        "step_count = 0\n",
        "episode_count = 1\n",
        "total_reward = 0\n",
        "\n",
        "try:\n",
        "    while running:\n",
        "        # Process events\n",
        "        for event in pygame.event.get():\n",
        "            if event.type == pygame.QUIT:\n",
        "                running = False\n",
        "            elif event.type == pygame.KEYDOWN:\n",
        "                if event.key == pygame.K_ESCAPE:\n",
        "                    running = False\n",
        "                elif event.key == pygame.K_r:\n",
        "                    print(\"ğŸ”„ Manual reset requested\")\n",
        "                    obs, _ = env.reset()\n",
        "                    step_count = 0\n",
        "                    total_reward = 0\n",
        "                    episode_count += 1\n",
        "                    print(f\"ğŸ†• Episode {episode_count} started\")\n",
        "\n",
        "        # Get currently pressed keys\n",
        "        keys = pygame.key.get_pressed()\n",
        "        \n",
        "        # Determine action based on keys (allow multiple keys)\n",
        "        old_action = action\n",
        "        if keys[pygame.K_UP]:\n",
        "            action = 2  # Main engine has priority\n",
        "            if old_action != action:\n",
        "                print(\"ğŸš€ MAIN ENGINE FIRING!\")\n",
        "        elif keys[pygame.K_LEFT]:\n",
        "            action = 1\n",
        "            if old_action != action:\n",
        "                print(\"ğŸ”¥ LEFT ENGINE FIRING!\")\n",
        "        elif keys[pygame.K_RIGHT]:\n",
        "            action = 3\n",
        "            if old_action != action:\n",
        "                print(\"ğŸ”¥ RIGHT ENGINE FIRING!\")\n",
        "        else:\n",
        "            action = 0\n",
        "            if old_action != action and old_action != 0:\n",
        "                print(\"â­• Engines off\")\n",
        "\n",
        "        # Step in the environment\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        step_count += 1\n",
        "        total_reward += reward\n",
        "\n",
        "        # Extract observation values (LunarLander has 8 observation values)\n",
        "        x_pos, y_pos, x_vel, y_vel, angle, angular_vel, left_leg, right_leg = obs\n",
        "        \n",
        "        # Print status every 20 steps or on important events\n",
        "        if step_count % 20 == 0 or terminated or truncated or abs(reward) > 10:\n",
        "            print(f\"Step {step_count:3d} | X: {x_pos:6.2f} | Y: {y_pos:6.2f} | \"\n",
        "                  f\"Vel: ({x_vel:5.2f},{y_vel:5.2f}) | Angle: {angle:5.2f} | \"\n",
        "                  f\"Reward: {reward:6.1f} | Total: {total_reward:6.1f}\")\n",
        "\n",
        "        # Give feedback on landing legs\n",
        "        if left_leg or right_leg:\n",
        "            if step_count % 10 == 0:  # Don't spam this message\n",
        "                legs_status = []\n",
        "                if left_leg:\n",
        "                    legs_status.append(\"LEFT\")\n",
        "                if right_leg:\n",
        "                    legs_status.append(\"RIGHT\")\n",
        "                print(f\"ğŸ¦µ Landing legs touching: {', '.join(legs_status)}\")\n",
        "\n",
        "        # Check for episode end\n",
        "        if terminated or truncated:\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            if terminated:\n",
        "                if total_reward >= 200:\n",
        "                    print(\"ğŸ‰ EXCELLENT LANDING! Perfect score!\")\n",
        "                elif total_reward >= 100:\n",
        "                    print(\"ğŸ‰ SUCCESSFUL LANDING! Well done!\")\n",
        "                elif total_reward >= 0:\n",
        "                    print(\"ğŸ‘ SAFE LANDING! Could be smoother, but good job!\")\n",
        "                elif total_reward >= -100:\n",
        "                    print(\"ğŸ’¥ ROUGH LANDING! You survived but damaged the lander.\")\n",
        "                else:\n",
        "                    print(\"ğŸ’¥ CRASH! The lander was destroyed.\")\n",
        "            else:\n",
        "                print(\"â° Time limit reached!\")\n",
        "            \n",
        "            print(f\"ğŸ“Š Episode {episode_count} Results:\")\n",
        "            print(f\"   Final Score: {total_reward:.1f}\")\n",
        "            print(f\"   Steps taken: {step_count}\")\n",
        "            print(f\"   Final position: ({x_pos:.2f}, {y_pos:.2f})\")\n",
        "            print(f\"   Final velocity: ({x_vel:.2f}, {y_vel:.2f})\")\n",
        "            \n",
        "            # Scoring breakdown\n",
        "            if total_reward >= 200:\n",
        "                print(\"ğŸ† RATING: EXPERT PILOT\")\n",
        "            elif total_reward >= 100:\n",
        "                print(\"ğŸ¥‡ RATING: SKILLED PILOT\") \n",
        "            elif total_reward >= 0:\n",
        "                print(\"ğŸ¥ˆ RATING: COMPETENT PILOT\")\n",
        "            elif total_reward >= -100:\n",
        "                print(\"ğŸ¥‰ RATING: NOVICE PILOT\")\n",
        "            else:\n",
        "                print(\"ğŸ’€ RATING: NEEDS MORE PRACTICE\")\n",
        "            \n",
        "            print(\"=\"*50)\n",
        "            print(\"ğŸ”„ Resetting in 3 seconds... (Press R to reset immediately)\")\n",
        "            \n",
        "            # Wait for reset or user input\n",
        "            start_time = time.time()\n",
        "            reset_now = False\n",
        "            while time.time() - start_time < 3 and not reset_now:\n",
        "                for event in pygame.event.get():\n",
        "                    if event.type == pygame.QUIT:\n",
        "                        running = False\n",
        "                        reset_now = True\n",
        "                    elif event.type == pygame.KEYDOWN:\n",
        "                        if event.key == pygame.K_ESCAPE:\n",
        "                            running = False\n",
        "                            reset_now = True\n",
        "                        elif event.key == pygame.K_r:\n",
        "                            reset_now = True\n",
        "                \n",
        "                clock.tick(60)  # Check events frequently during wait\n",
        "            \n",
        "            if running:\n",
        "                obs, _ = env.reset()\n",
        "                step_count = 0\n",
        "                total_reward = 0\n",
        "                episode_count += 1\n",
        "                print(f\"ğŸ†• Episode {episode_count} started\")\n",
        "\n",
        "        # Control frame rate\n",
        "        clock.tick(30)  # 30 FPS for smooth control\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nğŸ›‘ Interrupted by user (Ctrl+C)\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Runtime error: {e}\")\n",
        "finally:\n",
        "    print(\"ğŸ”š Closing environment...\")\n",
        "    env.close()\n",
        "    pygame.quit()\n",
        "    print(\"âœ… Cleanup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## ğŸš€ Play LunarLander Manually!\n",
        "\n",
        "def play_lunar_lander():\n",
        "    \"\"\"Interactive LunarLander game with keyboard controls\"\"\"\n",
        "    \n",
        "    try:\n",
        "        # Create environment with human rendering\n",
        "        env = gym.make('LunarLander-v2', render_mode='human')\n",
        "        agent = ManualAgent(env.action_space)\n",
        "        \n",
        "        # Initialize pygame for key detection\n",
        "        pygame.init()\n",
        "        pygame.display.set_mode((1, 1))  # Minimal display for key events\n",
        "        clock = pygame.time.Clock()\n",
        "        \n",
        "        print(\"ğŸš€ Starting Manual Control Mode...\")\n",
        "        print(\"Close this message and focus on the game window!\")\n",
        "        print(\"Use arrow keys to control the lander.\\n\")\n",
        "        \n",
        "        # Game statistics\n",
        "        episodes = 0\n",
        "        total_rewards = []\n",
        "        successful_landings = 0\n",
        "        \n",
        "        # Main game loop\n",
        "        game_running = True\n",
        "        while game_running:\n",
        "            episodes += 1\n",
        "            print(f\"\\nğŸš€ Episode {episodes} - New landing attempt!\")\n",
        "            \n",
        "            state, info = env.reset()\n",
        "            total_reward = 0\n",
        "            steps = 0\n",
        "            agent.set_action(0)  # Start with no action\n",
        "            \n",
        "            episode_running = True\n",
        "            while episode_running and game_running:\n",
        "                # Handle pygame events for key presses\n",
        "                for event in pygame.event.get():\n",
        "                    if event.type == pygame.QUIT:\n",
        "                        game_running = False\n",
        "                        episode_running = False\n",
        "                        break\n",
        "                    elif event.type == pygame.KEYDOWN:\n",
        "                        if event.key == pygame.K_LEFT:\n",
        "                            agent.set_action(1)  # Fire left engine\n",
        "                        elif event.key == pygame.K_RIGHT:\n",
        "                            agent.set_action(3)  # Fire right engine\n",
        "                        elif event.key == pygame.K_UP:\n",
        "                            agent.set_action(2)  # Fire main engine\n",
        "                        elif event.key == pygame.K_DOWN:\n",
        "                            agent.set_action(0)  # Do nothing\n",
        "                        elif event.key == pygame.K_r:\n",
        "                            print(\"ğŸ”„ Resetting episode...\")\n",
        "                            episode_running = False\n",
        "                            episodes -= 1  # Don't count reset as new episode\n",
        "                            break\n",
        "                        elif event.key in [pygame.K_ESCAPE, pygame.K_q]:\n",
        "                            game_running = False\n",
        "                            episode_running = False\n",
        "                            break\n",
        "                    elif event.type == pygame.KEYUP:\n",
        "                        # Stop action when key is released (except for DOWN)\n",
        "                        if event.key in [pygame.K_LEFT, pygame.K_RIGHT, pygame.K_UP]:\n",
        "                            agent.set_action(0)\n",
        "                \n",
        "                if not episode_running or not game_running:\n",
        "                    break\n",
        "                    \n",
        "                # Take action in environment\n",
        "                action = agent.select_action(state)\n",
        "                next_state, reward, terminated, truncated, info = env.step(action)\n",
        "                done = terminated or truncated\n",
        "                \n",
        "                total_reward += reward\n",
        "                steps += 1\n",
        "                state = next_state\n",
        "                \n",
        "                # Control game speed (60 FPS)\n",
        "                clock.tick(60)\n",
        "                \n",
        "                if done:\n",
        "                    success = total_reward >= 200\n",
        "                    decent = total_reward >= 100\n",
        "                    total_rewards.append(total_reward)\n",
        "                    \n",
        "                    if success:\n",
        "                        successful_landings += 1\n",
        "                    \n",
        "                    print(f\"\\nğŸ Episode {episodes} Complete!\")\n",
        "                    print(f\"   Duration: {steps} steps\")\n",
        "                    print(f\"   Total Reward: {total_reward:.1f}\")\n",
        "                    \n",
        "                    if success:\n",
        "                        print(f\"   Result: âœ… EXCELLENT LANDING! ğŸ‰\")\n",
        "                    elif decent:\n",
        "                        print(f\"   Result: ğŸŸ¡ Good landing attempt\")\n",
        "                    elif total_reward > 0:\n",
        "                        print(f\"   Result: ğŸŸ  Rough but safe landing\")\n",
        "                    else:\n",
        "                        print(f\"   Result: âŒ Crashed or failed\")\n",
        "                    \n",
        "                    if len(total_rewards) > 1:\n",
        "                        avg_score = np.mean(total_rewards)\n",
        "                        best_score = max(total_rewards)\n",
        "                        print(f\"   Average Score: {avg_score:.1f}\")\n",
        "                        print(f\"   Best Score: {best_score:.1f}\")\n",
        "                        print(f\"   Success Rate: {successful_landings}/{len(total_rewards)} ({successful_landings/len(total_rewards)*100:.1f}%)\")\n",
        "                    \n",
        "                    print(\"\\n   Press R for new episode, ESC/Q to quit...\")\n",
        "                    episode_running = False\n",
        "        \n",
        "        # Final statistics\n",
        "        env.close()\n",
        "        pygame.quit()\n",
        "        \n",
        "        if total_rewards:\n",
        "            print(f\"\\nğŸ® Game Over! Final Statistics:\")\n",
        "            print(f\"=\" * 40)\n",
        "            print(f\"ğŸ“Š Episodes Played: {len(total_rewards)}\")\n",
        "            print(f\"ğŸ† Successful Landings: {successful_landings}/{len(total_rewards)} ({successful_landings/len(total_rewards)*100:.1f}%)\")\n",
        "            print(f\"ğŸ“ˆ Average Score: {np.mean(total_rewards):.1f}\")\n",
        "            print(f\"ğŸ¥‡ Best Score: {max(total_rewards):.1f}\")\n",
        "            print(f\"ğŸ“‰ Worst Score: {min(total_rewards):.1f}\")\n",
        "            \n",
        "            # Compare with random agent\n",
        "            if 'avg_reward' in globals():\n",
        "                improvement = np.mean(total_rewards) - avg_reward\n",
        "                print(f\"\\nğŸ¤– vs ğŸ® Comparison:\")\n",
        "                print(f\"   Your average: {np.mean(total_rewards):.1f}\")\n",
        "                print(f\"   Random agent: {avg_reward:.1f}\")\n",
        "                print(f\"   Improvement: {improvement:+.1f} points ({improvement/abs(avg_reward)*100:+.1f}%)\")\n",
        "        \n",
        "        print(\"\\nğŸš€ Thanks for playing! You're now ready for RL algorithms!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error running manual control: {e}\")\n",
        "        print(\"ğŸ’¡ Make sure pygame is installed and display is available\")\n",
        "        print(\"   Try: pip install pygame\")\n",
        "\n",
        "# Instructions\n",
        "print(\"ğŸ® Ready to pilot the lunar lander manually?\")\n",
        "print(\"Run the cell below to start the interactive game!\")\n",
        "\n",
        "# Uncomment the line below to start the game\n",
        "# play_lunar_lander()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ Learning Summary\n",
        "\n",
        "Congratulations! You've completed the LunarLander RL basics tutorial. Let's review what you've learned:\n",
        "\n",
        "### ğŸ§  Key Concepts Mastered:\n",
        "\n",
        "1. **ğŸ—ï¸ MDP Components in Practice:**\n",
        "   - **States**: 8-dimensional continuous space (position, velocity, angle, etc.)\n",
        "   - **Actions**: 4 discrete actions (engines: none, left, main, right)\n",
        "   - **Rewards**: Continuous rewards based on landing performance\n",
        "   - **Transitions**: Physics-based state changes\n",
        "\n",
        "2. **ğŸ² Baseline Performance:**\n",
        "   - Random agents perform poorly (~0-20% success rate)\n",
        "   - Demonstrates the need for intelligent decision-making\n",
        "   - Shows the challenge of the environment\n",
        "\n",
        "3. **ğŸ® Human Intelligence:**\n",
        "   - Manual control significantly outperforms random actions\n",
        "   - Demonstrates the value of strategy and planning\n",
        "   - Shows what RL algorithms should aspire to achieve\n",
        "\n",
        "### ğŸš€ Next Steps in Your RL Journey:\n",
        "\n",
        "1. **ğŸ“š Algorithm Learning:**\n",
        "   - Q-Learning for discrete environments\n",
        "   - Policy Gradient methods for continuous control\n",
        "   - Deep RL for complex state spaces\n",
        "\n",
        "2. **ğŸ› ï¸ Implementation Skills:**\n",
        "   - Building RL agents from scratch\n",
        "   - Training and evaluation pipelines\n",
        "   - Hyperparameter tuning\n",
        "\n",
        "3. **ğŸ¯ Advanced Topics:**\n",
        "   - Multi-agent RL\n",
        "   - Transfer learning\n",
        "   - Real-world applications\n",
        "\n",
        "### ğŸ† Achievement Unlocked:\n",
        "- âœ… Environment Analysis Expert\n",
        "- âœ… Agent Implementation Basics\n",
        "- âœ… Performance Evaluation Skills\n",
        "\n",
        "\n",
        "**Ready for the next challenge? Let's dive into RL algorithms! ğŸš€**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ… Bonus Challenges\n",
        "\n",
        "Want to explore further? Try these challenges:\n",
        "\n",
        "### ğŸ¯ Challenge 1: Heuristic Agent\n",
        "Create a simple heuristic agent that uses basic rules:\n",
        "- Fire main engine when falling too fast\n",
        "- Use side engines to control rotation\n",
        "- Coast when trajectory looks good\n",
        "\n",
        "### ğŸ¯ Challenge 2: Environment Variations\n",
        "Try different LunarLander variants:\n",
        "- `LunarLander-v2` (standard)\n",
        "- `LunarLanderContinuous-v2` (continuous actions)\n",
        "- Different gravity settings\n",
        "\n",
        "### ğŸ¯ Challenge 3: Data Collection\n",
        "Collect and analyze data from your manual play:\n",
        "- State trajectories\n",
        "- Action sequences\n",
        "- Reward patterns\n",
        "- Success factors\n",
        "\n",
        "### ğŸ¯ Challenge 4: Visualization\n",
        "Create visualizations of:\n",
        "- Landing trajectories\n",
        "- Action usage patterns\n",
        "- Learning curves\n",
        "- State space exploration\n",
        "\n",
        "### ğŸ¯ Challenge 5: Mini RL Algorithm\n",
        "Implement a simple learning algorithm:\n",
        "- Tabular Q-learning (discretize states)\n",
        "- Simple policy gradient\n",
        "- Behavioral cloning from your manual play\n",
        "\n",
        "**Good luck, future RL engineer! ğŸš€**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
